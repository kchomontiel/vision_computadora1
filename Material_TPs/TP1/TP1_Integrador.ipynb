{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP1\n",
    "\n",
    "**Parte 1**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1 - Pasaje a coordenadas cromáticas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt # pip install PyQt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chromaticCoordinates(imgRGB):#castear todo a float las 6 variables\n",
    "    im_r, im_g, im_b = cv.split(imgRGB)\n",
    "    \n",
    "    CC_r = np.zeros((im_r.shape[0], im_r.shape[1]))\n",
    "    CC_g = np.zeros((im_r.shape[0], im_r.shape[1]))\n",
    "    CC_b = np.zeros((im_r.shape[0], im_r.shape[1]))\n",
    "\n",
    "    im_r = im_r.astype(float)\n",
    "    im_g = im_g.astype(float)\n",
    "    im_b = im_b.astype(float)\n",
    "    \n",
    "    CC_r = CC_r.astype(float)\n",
    "    CC_g = CC_g.astype(float)\n",
    "    CC_b = CC_b.astype(float)\n",
    "\n",
    "    for column in range(0, im_r.shape[0]):\n",
    "        for row in range(0, im_r.shape[1]):\n",
    "            R_pixel = im_r[column][row]\n",
    "            G_pixel = im_g[column][row]\n",
    "            B_pixel = im_b[column][row]\n",
    "            currentPixelSum = float(R_pixel+G_pixel+B_pixel)\n",
    "            #print(\"R: \",R_pixel,\",G: \",G_pixel,\",B: \",B_pixel,\"=\",currentPixelSum)\n",
    "            if currentPixelSum == 0:\n",
    "                CC_r[column][row] = 0\n",
    "                CC_g[column][row] = 0\n",
    "                CC_b[column][row] = 0\n",
    "                #print(\"Valor de currentPixelSum es 0 en [\",column,\"][\",row,\"]\")\n",
    "            else:\n",
    "                CC_r[column][row] = float(R_pixel/currentPixelSum)\n",
    "                CC_g[column][row] = float(G_pixel/currentPixelSum)\n",
    "                CC_b[column][row] = float(B_pixel/currentPixelSum)\n",
    "    imgCC = cv.merge((CC_r, CC_g, CC_b))\n",
    "    plt.imshow(imgCC)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"./coord_cromaticas/CoordCrom_2.png\")\n",
    "imgRGB = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "chromaticCoordinates(imgRGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2 - White Patch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(channel):\n",
    "    min_value = min(channel.flatten())\n",
    "    max_value = max(channel.flatten())\n",
    "    for column in range(0, channel.shape[0]):\n",
    "        for row in range(0, channel.shape[1]):\n",
    "            valor = channel[column][row]\n",
    "            channel[column][row] = (valor - min_value) / \\\n",
    "                (max_value - min_value) * 255\n",
    "    return np.uint8(channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setWhitePatch(imgRGB):\n",
    "    im_r, im_g, im_b = cv.split(imgRGB)\n",
    "    R_max_value = max(im_r.flatten())\n",
    "    # print(\"Max value in R \",R_max_value);\n",
    "    G_max_value = max(im_g.flatten())\n",
    "    # print(\"Max value in G \",G_max_value);\n",
    "    B_max_value = max(im_b.flatten())\n",
    "    # print(\"Max value in B \",B_max_value);\n",
    "    R_channel = normalize(np.uint8((255/R_max_value)*im_r))\n",
    "    G_channel = normalize(np.uint8((255/G_max_value)*im_g))\n",
    "    B_channel = normalize(np.uint8((255/B_max_value)*im_b))\n",
    "    imgWhitePatch = cv.merge((R_channel, G_channel, B_channel))\n",
    "    plt.imshow(imgWhitePatch)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"./white_patch/test_red.png\")\n",
    "imgRGB = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "setWhitePatch(imgRGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"./white_patch/test_green.png\")\n",
    "imgRGB = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "setWhitePatch(imgRGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"./white_patch/test_blue.png\")\n",
    "imgRGB = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "setWhitePatch(imgRGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"./white_patch/wp_red.png\")\n",
    "imgRGB = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "setWhitePatch(imgRGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"./white_patch/wp_red2.jpg\")\n",
    "imgRGB = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "setWhitePatch(imgRGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"./white_patch/wp_green.png\")\n",
    "imgRGB = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "setWhitePatch(imgRGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"./white_patch/wp_green2.jpg\")\n",
    "imgRGB = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "setWhitePatch(imgRGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"./white_patch/wp_blue.jpg\")\n",
    "imgRGB = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "setWhitePatch(imgRGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos concluir que para las primeras imagenes test_blue, test_green y test_red\n",
    "se pudo eliminar por completo los colores y aplicamos con exito el white patch.\n",
    "Mientras que para las siguientes imagenes con prefijo wp no tuvimos tanto exito.\n",
    "en el caso de las imagenes mas pequeñas se nota mas el trabajo del filtro pero\n",
    "en las imagenes (wp_blue.jpg, wp_green2.jpg, wp_red2.jpg) no se puede denotar\n",
    "mucha diferencia con las imagenes originales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parte 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1 - Leer con OpenCV en escala de grises y visualizar imagenes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv.imread('img1_tp.png', cv.IMREAD_GRAYSCALE)\n",
    "img2 = cv.imread('img2_tp.png', cv.IMREAD_GRAYSCALE)\n",
    "cv.imshow(\"img1\",img1)\n",
    "cv.imshow(\"img2\",img2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2 - Histogramas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pltimg(img,title):\n",
    "    # Nueva figura\n",
    "    fig = plt.figure()\n",
    "\n",
    "    # Imagen original\n",
    "    ax1=plt.subplot(221)\n",
    "    ax1.imshow(img, cmap='gray', vmin=0, vmax=255)\n",
    "    ax1.set_title(title)\n",
    "\n",
    "    hist1,bins1 = np.histogram(img.ravel(),256,[0,256])\n",
    "    ax3=plt.subplot(223)\n",
    "    ax3.plot(hist1)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pltimg(img1,'img1')\n",
    "pltimg(img2,'img2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede denotar que los histogramas muy similares para no decir iguales.\n",
    "Creo que no seria buena idea tomar los histogramas com feaures, porque\n",
    "puede pasar como en este caso dos imagenes visiblemente diferentes cuentan con\n",
    "el histograma muy semejante, no teniendo asi caracteristicas identificatorias\n",
    "para cada una de las imagenes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3 - Segmentacion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgbHistograms(imgRGB):\n",
    "    im_r, im_g, im_b = cv.split(imgRGB)\n",
    "    pltimg(im_r,'R Channel')\n",
    "    pltimg(im_g,'G Channel')\n",
    "    pltimg(im_b,'B Channel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"./segmentacion.png\")\n",
    "imgRGB = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "rgbHistograms(imgRGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imgSegmentation(img_muestra,imgRGB,colorType,l_Inferior,l_Superior):\n",
    "    img_HSV = cv.cvtColor(imgRGB, colorType)\n",
    "    color_mean = cv.mean(img_muestra)\n",
    "    print(color_mean)\n",
    "\n",
    "    color_l = (color_mean[0]-l_Inferior[0],l_Inferior[1],l_Inferior[2])\n",
    "    color_u = (color_mean[0]+l_Superior[0],l_Superior[1],l_Superior[2])\n",
    "\n",
    "    mask = cv.inRange(img_HSV, color_l,  color_u)\n",
    "    img_segmentada = cv.bitwise_and(imgRGB, imgRGB, mask=mask)\n",
    "\n",
    "    plt.figure(6)\n",
    "    plt.imshow(img_segmentada)\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tomamos la muestra del cielo\n",
    "img_muestra1 = imgRGB[50:200,500:900,:]\n",
    "plt.figure(2)\n",
    "plt.imshow(img_muestra1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tomamos la muestra de la costa\n",
    "img_muestra2 = imgRGB[450:600,150:500,:]\n",
    "plt.figure(2)\n",
    "plt.imshow(img_muestra2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tomamos la muestra del mar\n",
    "img_muestra3 = imgRGB[305:380,450:900,:]\n",
    "plt.figure(2)\n",
    "plt.imshow(img_muestra3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82.69023333333334, 170.42413333333334, 231.817, 0.0)\n"
     ]
    }
   ],
   "source": [
    "# Definimos el limite superior y el limite inferior para la segmentacion de \n",
    "# la muestra 1\n",
    "l_Inferior=[20,20,150]\n",
    "l_Superior=[25,255,255]\n",
    "imgSegmentation(img_muestra1,imgRGB,cv.COLOR_RGB2HSV,l_Inferior,l_Superior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(94.99607619047619, 74.2892, 45.42337142857143, 0.0)\n"
     ]
    }
   ],
   "source": [
    "# Definimos el limite superior y el limite inferior para la segmentacion de \n",
    "# la muestra 2\n",
    "l_Inferior=[0,0,0]\n",
    "l_Superior=[250,255,180]\n",
    "imgSegmentation(img_muestra2,imgRGB,cv.COLOR_RGB2HSV,l_Inferior,l_Superior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74.71146666666667, 122.25795555555555, 135.83155555555555, 0.0)\n"
     ]
    }
   ],
   "source": [
    "# Definimos el limite superior y el limite inferior para la segmentacion de \n",
    "# la muestra 3\n",
    "l_Inferior=[10,0,0]\n",
    "l_Superior=[30,255,255]\n",
    "imgSegmentation(img_muestra3,imgRGB,cv.COLOR_BGR2HSV,l_Inferior,l_Superior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pudimos realizar el trabajo de segmentacion de las 3 muestras, teniendo mas\n",
    "dificultad entre el mar y el cielo ya que sus colores son similares, pero\n",
    "definiendo los limites correctos es posible realizar una buena segmentacion."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 ('vision-robotica')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "0af437b5139b375ee3fab2b21e8a1376590e14b3c752e237587dc080bd8d5be3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
